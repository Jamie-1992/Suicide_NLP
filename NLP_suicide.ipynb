{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suicide prediction with natural language processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "text          0\n",
      "class         0\n",
      "dtype: int64\n",
      "   Unnamed: 0                                               text        class\n",
      "0           2  Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
      "1           3  Am I weird I don't get affected by compliments...  non-suicide\n",
      "2           4  Finally 2020 is almost over... So I can never ...  non-suicide\n",
      "3           8          i need helpjust help me im crying so hard      suicide\n",
      "4           9  I’m so lostHello, my name is Adam (16) and I’v...      suicide\n",
      "5          11  Honetly idkI dont know what im even doing here...      suicide\n",
      "6          12  [Trigger warning] Excuse for self inflicted bu...      suicide\n",
      "7          13   It ends tonight.I can’t do it anymore. \\nI quit.      suicide\n",
      "8          16  Everyone wants to be \"edgy\" and it's making me...  non-suicide\n",
      "9          18  My life is over at 20 years oldHello all. I am...      suicide\n",
      "suicide        116037\n",
      "non-suicide    116037\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Suicide = pd.read_csv(\"Suicide_Detection.csv\")\n",
    "print(Suicide.isnull().sum()) #No missing values. \n",
    "print(Suicide.head(n = 10))\n",
    "\n",
    "print(Suicide[\"class\"].value_counts()) #Perfect balance between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 1]\n",
      "Original letter encoding  0         suicide\n",
      "1     non-suicide\n",
      "2     non-suicide\n",
      "3         suicide\n",
      "4         suicide\n",
      "5         suicide\n",
      "6         suicide\n",
      "7         suicide\n",
      "8     non-suicide\n",
      "9         suicide\n",
      "10        suicide\n",
      "11        suicide\n",
      "12        suicide\n",
      "13        suicide\n",
      "14        suicide\n",
      "Name: class, dtype: object\n",
      "Label encoding transformed non-suicide = 0 and suicide = 1 [1 0 0 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>targ_tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I’m so lostHello, my name is Adam (16) and I’v...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Honetly idkI dont know what im even doing here...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>[Trigger warning] Excuse for self inflicted bu...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>It ends tonight.I can’t do it anymore. \\nI quit.</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>Everyone wants to be \"edgy\" and it's making me...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>My life is over at 20 years oldHello all. I am...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  Ex Wife Threatening SuicideRecently I left my ...      suicide   \n",
       "1           3  Am I weird I don't get affected by compliments...  non-suicide   \n",
       "2           4  Finally 2020 is almost over... So I can never ...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  I’m so lostHello, my name is Adam (16) and I’v...      suicide   \n",
       "5          11  Honetly idkI dont know what im even doing here...      suicide   \n",
       "6          12  [Trigger warning] Excuse for self inflicted bu...      suicide   \n",
       "7          13   It ends tonight.I can’t do it anymore. \\nI quit.      suicide   \n",
       "8          16  Everyone wants to be \"edgy\" and it's making me...  non-suicide   \n",
       "9          18  My life is over at 20 years oldHello all. I am...      suicide   \n",
       "\n",
       "   targ_tran  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  \n",
       "8          0  \n",
       "9          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = Suicide['class']\n",
    "lab = LabelEncoder()\n",
    "lab.fit(target)\n",
    "targ_tran = lab.transform(target)\n",
    "print(targ_tran[:10])\n",
    "\n",
    "print(\"Original letter encoding \",  target[:15])\n",
    "print(\"Label encoding transformed non-suicide = 0 and suicide = 1\", targ_tran[:10])\n",
    "\n",
    "Suicide['targ_tran'] = targ_tran #adding transformed variable to data frame\n",
    "Suicide.head(n= 10) #Can see new transformed variable next to original target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Keeping 60000 most common words \n",
    "toke = Tokenizer(num_words = 60000, lower = 1, oov_token = \"<OOV>\", filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "toke.fit_on_texts(Suicide['text'])\n",
    "word_index = toke.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203027"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index) #203,027 words were found in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Each sample will be a list of integers: each interger refers to a word which was done previous panel\n",
    "Seq = toke.texts_to_sequences(Suicide['text'])\n",
    "print(len(Seq[4])) #First sample has 27 words \n",
    "print(type(Seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "#Padding. #Each text sample will be padded with 0's at the end to equal same length as longest sample.\n",
    "pad = pad_sequences(Seq, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232074\n",
      "232074\n",
      "232074\n"
     ]
    }
   ],
   "source": [
    "#Each text sample been transformed to a sequence of integers that represent words \n",
    "print(len(Seq))\n",
    "print(len(Suicide['text']))\n",
    "print(len(pad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature matrix and target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87027.5\n",
      "58019\n",
      "174055\n",
      "58019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pad \n",
    "y = Suicide['targ_tran']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, shuffle = True)\n",
    "\n",
    "print(len(X_train)/2) #half will go into training and half will go into validation when running the neural network\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 30)          1800000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 30)          120       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 1,801,711\n",
      "Trainable params: 1,801,561\n",
      "Non-trainable params: 150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout \n",
    "from tensorflow import keras\n",
    "\n",
    "voc_size = 60000 \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim = voc_size, output_dim = 30),\n",
    "    BatchNormalization(),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    \n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5), \n",
    "    \n",
    "    keras.layers.Dense(15, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Dense(1, activation = 'sigmoid'),\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2720/2720 - 1089s - loss: 0.4015 - accuracy: 0.8289 - val_loss: 1.3487 - val_accuracy: 0.5507\n",
      "Epoch 2/50\n",
      "2720/2720 - 1279s - loss: 0.2623 - accuracy: 0.9014 - val_loss: 1.2310 - val_accuracy: 0.6296\n",
      "Epoch 3/50\n",
      "2720/2720 - 1021s - loss: 0.2329 - accuracy: 0.9150 - val_loss: 0.6440 - val_accuracy: 0.6813\n",
      "Epoch 4/50\n",
      "2720/2720 - 926s - loss: 0.2179 - accuracy: 0.9204 - val_loss: 2.8032 - val_accuracy: 0.5016\n",
      "Epoch 5/50\n",
      "2720/2720 - 911s - loss: 0.2079 - accuracy: 0.9234 - val_loss: 17.4440 - val_accuracy: 0.5002\n",
      "Epoch 6/50\n",
      "2720/2720 - 919s - loss: 0.1934 - accuracy: 0.9300 - val_loss: 0.4488 - val_accuracy: 0.7126\n",
      "Epoch 7/50\n",
      "2720/2720 - 906s - loss: 0.1863 - accuracy: 0.9324 - val_loss: 2.8293 - val_accuracy: 0.5043\n",
      "Epoch 8/50\n",
      "2720/2720 - 918s - loss: 0.1809 - accuracy: 0.9357 - val_loss: 2.2244 - val_accuracy: 0.5027\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "2720/2720 - 916s - loss: 0.1758 - accuracy: 0.9374 - val_loss: 21.0932 - val_accuracy: 0.5013\n",
      "Epoch 10/50\n",
      "2720/2720 - 1165s - loss: 0.1698 - accuracy: 0.9393 - val_loss: 3.9120 - val_accuracy: 0.5022\n",
      "Epoch 11/50\n",
      "2720/2720 - 1207s - loss: 0.1639 - accuracy: 0.9420 - val_loss: 1.8289 - val_accuracy: 0.5027\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "2720/2720 - 1196s - loss: 0.1605 - accuracy: 0.9425 - val_loss: 3.9621 - val_accuracy: 0.6049\n",
      "Epoch 13/50\n",
      "2720/2720 - 1178s - loss: 0.1566 - accuracy: 0.9450 - val_loss: 0.7140 - val_accuracy: 0.5847\n",
      "Epoch 14/50\n",
      "2720/2720 - 959s - loss: 0.1544 - accuracy: 0.9443 - val_loss: 1.3967 - val_accuracy: 0.6530\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "2720/2720 - 977s - loss: 0.1464 - accuracy: 0.9487 - val_loss: 12.6057 - val_accuracy: 0.5312\n",
      "Epoch 16/50\n",
      "2720/2720 - 1026s - loss: 0.1465 - accuracy: 0.9480 - val_loss: 0.5547 - val_accuracy: 0.8175\n",
      "Epoch 17/50\n",
      "2720/2720 - 1201s - loss: 0.1435 - accuracy: 0.9493 - val_loss: 1.6029 - val_accuracy: 0.5279\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "2720/2720 - 1114s - loss: 0.1416 - accuracy: 0.9497 - val_loss: 12.9443 - val_accuracy: 0.5037\n",
      "Epoch 19/50\n",
      "2720/2720 - 945s - loss: 0.1383 - accuracy: 0.9519 - val_loss: 2.1275 - val_accuracy: 0.6561\n",
      "Epoch 20/50\n",
      "2720/2720 - 914s - loss: 0.1340 - accuracy: 0.9525 - val_loss: 0.2375 - val_accuracy: 0.9208\n",
      "Epoch 21/50\n",
      "2720/2720 - 909s - loss: 0.1324 - accuracy: 0.9543 - val_loss: 8.9279 - val_accuracy: 0.5147\n",
      "Epoch 22/50\n",
      "2720/2720 - 913s - loss: 0.1304 - accuracy: 0.9549 - val_loss: 4.1373 - val_accuracy: 0.6322\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b68565a9dd21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpartial_ytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m87027\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m model.fit(partial_Xtrain,\n\u001b[0m\u001b[0;32m     20\u001b[0m          \u001b[0mpartial_ytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m          \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam \n",
    "\n",
    "#Call backs while training to reduce learning rate or stop the training if val accuracy does not improve\n",
    "learn_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose = 1)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience= 10, mode='auto', verbose = 1)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.0001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#Dividing training data to add half to validation\n",
    "\n",
    "x_val = X_train[:87027]\n",
    "partial_Xtrain = X_train[87027:]\n",
    "\n",
    "y_val = y_train[:87027]\n",
    "partial_ytrain = y_train[87027:]\n",
    "\n",
    "model.fit(partial_Xtrain,\n",
    "         partial_ytrain,\n",
    "         epochs = 50,\n",
    "         batch_size = 32,\n",
    "         validation_data = (x_val, y_val),\n",
    "         verbose = 2,\n",
    "         callbacks = [learn_reduce, early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model 1 on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 [==============================] - 158s 58ms/step - loss: 1.3531 - accuracy: 0.7613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3531148433685303, 0.7612580060958862]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 30)          1800000   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 30)          120       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 1,801,711\n",
      "Trainable params: 1,801,561\n",
      "Non-trainable params: 150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout \n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "voc_size = 60000 \n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim = voc_size, output_dim = 30),\n",
    "    BatchNormalization(),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    \n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5), \n",
    "    \n",
    "    keras.layers.Dense(15, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Dense(1, activation = 'sigmoid'),\n",
    "\n",
    "])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2720/2720 - 973s - loss: 0.4386 - accuracy: 0.8103 - val_loss: 0.5848 - val_accuracy: 0.6071\n",
      "Epoch 2/3\n",
      "2720/2720 - 899s - loss: 0.2665 - accuracy: 0.9004 - val_loss: 9.9949 - val_accuracy: 0.5106\n",
      "Epoch 3/3\n",
      "2720/2720 - 902s - loss: 0.2347 - accuracy: 0.9138 - val_loss: 0.4825 - val_accuracy: 0.6641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1381322c370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer = Adam(learning_rate = 0.0001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "x_val = X_train[:87027]\n",
    "partial_Xtrain = X_train[87027:]\n",
    "\n",
    "y_val = y_train[:87027]\n",
    "partial_ytrain = y_train[87027:]\n",
    "\n",
    "model2.fit(partial_Xtrain,\n",
    "         partial_ytrain,\n",
    "         epochs = 3,\n",
    "         batch_size = 32,\n",
    "         validation_data = (x_val, y_val),\n",
    "         verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model 2 on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814/1814 [==============================] - 110s 61ms/step - loss: 0.4867 - accuracy: 0.6603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48672303557395935, 0.6602836847305298]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
